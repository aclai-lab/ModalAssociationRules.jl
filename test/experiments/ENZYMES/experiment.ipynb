{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb9c7cee",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a6563",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "using Graphs\n",
    "using Serialization\n",
    "\n",
    "using ModalAssociationRules\n",
    "using SoleLogics: World, randframe\n",
    "using SoleLogics: KripkeStructure, ExplicitCrispUniModalFrame\n",
    "\n",
    "# dependencies for graph plotting\n",
    "using Plots\n",
    "using GraphPlot\n",
    "using Compose\n",
    "import Cairo, Fontconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac6666",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "WORKING_DIRECTORY = joinpath(@__DIR__, \"test\", \"experiments\", \"ENZYMES\")\n",
    "\n",
    "# the association rules are serialized in this repository\n",
    "RULES_REPOSITORY = joinpath(WORKING_DIRECTORY, \"rules\")\n",
    "# the miners are serialized in this repository\n",
    "MINERS_REPOSITORY = joinpath(WORKING_DIRECTORY, \"miners\")\n",
    "# the final analysis is saved in this repository\n",
    "RESULTS_REPOSITORY = joinpath(WORKING_DIRECTORY, \"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d21623d",
   "metadata": {},
   "source": [
    "# ENZYMES loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a43305",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# load ENZYMES dataset\n",
    "DATA_REPOSITORY = joinpath(WORKING_DIRECTORY, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be35a7c0",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# every label is one of the 6 types of enzymes;\n",
    "# the dataset is balanced, with 100 enzymes of each type.\n",
    "LABELS_FILENAME = joinpath(DATA_REPOSITORY, \"ENZYMES_graph_labels.txt\")\n",
    "labels = parse.(Int, split(read(LABELS_FILENAME, String) |> strip, \"\\n\") .|> String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff72c3e",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# every node belongs to one of the 600 total graphs\n",
    "GRAPH_INDICATOR_FILENAME = joinpath(DATA_REPOSITORY, \"ENZYMES_graph_indicator.txt\")\n",
    "node_to_graph = parse.(\n",
    "    Int,\n",
    "    split(read(GRAPH_INDICATOR_FILENAME, String) |> strip, \"\\n\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea6149",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# every node encodes one of the three possible protein SSE (secondary structure element)\n",
    "# 1: helix (a total of 9457 nodes)\n",
    "# 2: sheet (a total of 9665 nodes)\n",
    "# 3: turn (a total of 458 nodes)\n",
    "NODE_LABELS_FILENAME = joinpath(DATA_REPOSITORY, \"ENZYMES_node_labels.txt\")\n",
    "node_labels = parse.(\n",
    "    Int,\n",
    "    split(read(NODE_LABELS_FILENAME, String) |> strip, \"\\n\")\n",
    ")\n",
    "# this is needed later, since we are going to let nodes start from 1 in every new graph\n",
    "# and we do not want to lose the reference to the corresponding label of the node\n",
    "graph_and_ithnode_to_label = Dict{Tuple{Int,Int},Int}()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424f82bf",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# the effective graph structure\n",
    "EDGES_FILENAME = joinpath(DATA_REPOSITORY, \"ENZYMES_A.txt\")\n",
    "edges = [\n",
    "    parse.(Int, strip.(split(s, \",\"))) |> Tuple\n",
    "    for s in split(read(EDGES_FILENAME, String) |> strip, \"\\n\")\n",
    "]\n",
    "\n",
    "# mapping from node to neighbor\n",
    "from_to = Dict([\n",
    "    u => v\n",
    "    for (u,v) in edges\n",
    "])\n",
    "\n",
    "\n",
    "# convert the id of a node (1,2 or 3) to the corresponding secondary structure element;\n",
    "# 1 is helix, 2 is sheet, 3 is turn\n",
    "function id_to_sse(id::Int)\n",
    "    return id == 1 ? \"h\" : (id == 2 ? \"s\" : \"t\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d43309",
   "metadata": {},
   "source": [
    "Every enzyme must be converted into a KripkeFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c69d20e",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# compose the effective graph structure (i encodes the ith graph)\n",
    "kripkeframes = ExplicitCrispUniModalFrame[]\n",
    "rawgraphs = SimpleGraph[]\n",
    "\n",
    "for i in 1:600\n",
    "    # retrieve all the nodes of the ith graph\n",
    "    _nodes = findall(x -> x == i, node_to_graph)\n",
    "\n",
    "    # we want the worlds to start at 1, by adding a normalization scalar (scalar)\n",
    "    scalar = minimum(_nodes) - 1\n",
    "\n",
    "    # create the graph\n",
    "    graph = Graphs.SimpleGraph(length(_nodes))\n",
    "\n",
    "    for n in _nodes\n",
    "        # push the edge associated with n into the graph, if it exists\n",
    "        neighbor = get(from_to, n, nothing)\n",
    "        if !isnothing(neighbor)\n",
    "            Graphs.add_edge!(graph, n-scalar, neighbor-scalar)\n",
    "        end\n",
    "\n",
    "        # also, associate the (n-scalar)-th node in the ith graph with the corresponding label\n",
    "        graph_and_ithnode_to_label[(i,n-scalar)] = node_labels[n]\n",
    "    end\n",
    "\n",
    "    # collect raw graphs for possible visualization purposes\n",
    "    push!(rawgraphs, graph)\n",
    "\n",
    "    # create the kripke frame\n",
    "    worlds = World.(1:length(_nodes))\n",
    "    push!(kripkeframes, SoleLogics.ExplicitCrispUniModalFrame(worlds, graph))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f2d47",
   "metadata": {},
   "source": [
    "Now, it is time to define the alphabet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b482fcf",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# fundamental propositions\n",
    "helix, nothelix = Atom(\"h\"), NEGATION(Atom(\"h\"))\n",
    "sheet, notsheet = Atom(\"s\"), NEGATION(Atom(\"s\"))\n",
    "turn, notturn = Atom(\"t\"), NEGATION(Atom(\"t\"))\n",
    "\n",
    "# base alphabet that is enriched in various manners\n",
    "seed_alphabet = SyntaxTree[helix, sheet, turn]\n",
    "\n",
    "propositional_alphabet = convert(Vector{SyntaxTree}, deepcopy(seed_alphabet))\n",
    "\n",
    "# box and diamond up to modal depth 1\n",
    "for op in [DIAMOND, BOX]\n",
    "    for p in seed_alphabet\n",
    "        push!(propositional_alphabet, op(p))\n",
    "    end\n",
    "end\n",
    "\n",
    "# all the combinations of box and diamond up to modal depth 2\n",
    "for ((op1, op2)) in Iterators.product([DIAMOND, BOX], [DIAMOND, BOX])\n",
    "    for p in Iterators.flatten([seed_alphabet])\n",
    "        push!(propositional_alphabet, op1(op2(p)))\n",
    "    end\n",
    "end\n",
    "\n",
    "_atoms = [helix, sheet, turn]\n",
    "for _atom in _atoms\n",
    "    push!(propositional_alphabet, DIAMOND(DIAMOND(DIAMOND(_atoms))))\n",
    "    push!(propositional_alphabet, DIAMOND(DIAMOND(DIAMOND(DIAMOND(_atoms)))))\n",
    "    push!(propositional_alphabet, BOX(BOX(BOX(_atoms))))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3b121e",
   "metadata": {},
   "source": [
    "We can enrich every KripkeFrame with the new propositions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1c2115",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# every world within each frame has to be enriched with one atom encoding the\n",
    "# secondary structure element of a protein\n",
    "modaldataset = KripkeStructure[]\n",
    "\n",
    "for (i,kripkeframe) in enumerate(kripkeframes)\n",
    "    valuation = Dict([\n",
    "        w => begin\n",
    "            all_labels = [\"h\", \"s\", \"t\"]\n",
    "            toplabel = (graph_and_ithnode_to_label[(i, w.name)]) |> id_to_sse\n",
    "            botlabel = [l for l in all_labels if l != toplabel]\n",
    "\n",
    "            # we only deal with three propositional symbols, h, s, and t.\n",
    "            TruthDict([\n",
    "                Atom(toplabel) => TOP,\n",
    "                Atom(botlabel[1]) => BOT,\n",
    "                Atom(botlabel[2]) => BOT\n",
    "            ])\n",
    "        end\n",
    "        for w in kripkeframe.worlds\n",
    "    ])\n",
    "\n",
    "    push!(modaldataset, KripkeStructure(kripkeframe, valuation))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dfe703",
   "metadata": {},
   "source": [
    "We are reading for the mining process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3fbc50",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "_items = Item.(propositional_alphabet)\n",
    "\n",
    "\n",
    "# partition the modal dataset into the six groups of enzymes\n",
    "_mask_indexes = id -> findall(x -> x == id, labels)\n",
    "# Oxidoreductases\n",
    "MODAL_DATASET_1 = modaldataset[_mask_indexes(1)] |> Logiset\n",
    "# Transferases\n",
    "MODAL_DATASET_2 = modaldataset[_mask_indexes(2)] |> Logiset\n",
    "# Hydrolases\n",
    "MODAL_DATASET_3 = modaldataset[_mask_indexes(3)] |> Logiset\n",
    "# Lyases\n",
    "MODAL_DATASET_4 = modaldataset[_mask_indexes(4)] |> Logiset\n",
    "# Isomerases\n",
    "MODAL_DATASET_5 = modaldataset[_mask_indexes(5)] |> Logiset\n",
    "# Ligases\n",
    "MODAL_DATASET_6 = modaldataset[_mask_indexes(6)] |> Logiset\n",
    "\n",
    "\n",
    "# full dataset\n",
    "MODAL_DATASET_FULL = vcat(\n",
    "    modaldataset[_mask_indexes(1)]...,\n",
    "    modaldataset[_mask_indexes(2)]...,\n",
    "    modaldataset[_mask_indexes(3)]...,\n",
    "    modaldataset[_mask_indexes(4)]...,\n",
    "    modaldataset[_mask_indexes(5)]...,\n",
    "    modaldataset[_mask_indexes(6)]...,\n",
    ") |> Logiset\n",
    "\n",
    "\n",
    "datasets = [\n",
    "    MODAL_DATASET_1,\n",
    "    MODAL_DATASET_2,\n",
    "    MODAL_DATASET_3,\n",
    "    MODAL_DATASET_4,\n",
    "    MODAL_DATASET_5,\n",
    "    MODAL_DATASET_6,\n",
    "]\n",
    "\n",
    "datasetnames = [\n",
    "    \"Oxidoreductases\",\n",
    "    \"Transferases\",\n",
    "    \"Hydrolases\",\n",
    "    \"Lyases\",\n",
    "    \"Isomerases\",\n",
    "    \"Ligases\",\n",
    "]\n",
    "\n",
    "rules = Vector{Vector{ARule}}()\n",
    "\n",
    "# estimated number of match to consider a pattern to be frequent within a modal instance\n",
    "ADAPTIVE_LSUPP_THRESHOLD_FACTOR = 15 # 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6661dc4",
   "metadata": {},
   "source": [
    "This is where the actual mining happens.\n",
    "The filled miners and the extracted association rules are serialized in the `miner` and `rules` folders, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e2b343",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "for (i,_dataset) in enumerate([\n",
    "        MODAL_DATASET_1\n",
    "        MODAL_DATASET_2\n",
    "        MODAL_DATASET_3\n",
    "        MODAL_DATASET_4\n",
    "        MODAL_DATASET_5\n",
    "        MODAL_DATASET_6\n",
    "    ])\n",
    "\n",
    "    println(\"Mining $i-th enzyme\")\n",
    "\n",
    "    _instances = _dataset |> instances\n",
    "    _lsupp_threshold = ADAPTIVE_LSUPP_THRESHOLD_FACTOR / (\n",
    "        sum(x -> length(x.frame.worlds), _instances) / (length(_instances))\n",
    "    )\n",
    "\n",
    "    miner = Miner(\n",
    "        _dataset,\n",
    "        eclat,\n",
    "        _items,\n",
    "        [(gsupport, 0.1, 0.05)],\n",
    "        [(gconfidence, 0.1, 0.5), (glift, 0.5, 2.0)],\n",
    "        itemset_policies=Function[\n",
    "            isanchored_itemset(ignoreuntillength=1)\n",
    "        ],\n",
    "        arule_policies=Function[\n",
    "            isanchored_arule()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    debugminer = miner\n",
    "\n",
    "    mine!(miner)\n",
    "\n",
    "    push!(rules, arules(miner))\n",
    "\n",
    "    # we serialize each miner\n",
    "    serialize(\n",
    "        joinpath(MINERS_REPOSITORY, \"miner_$i\"),\n",
    "        miner\n",
    "    )\n",
    "end\n",
    "\n",
    "# we serialize each group of rules\n",
    "for (i,rulegroup) in enumerate(rules)\n",
    "    serialize(\n",
    "        joinpath(RULES_REPOSITORY, \"enzymes_$i\"),\n",
    "        rulegroup\n",
    "    )\n",
    "end\n",
    "\n",
    "# overwrite rules with the serialized ones, and interpret them as sets;\n",
    "_nclasses = 6\n",
    "rulesets = [Set{ARule}() for _ in 1:_nclasses]\n",
    "for i in 1:length(rules)\n",
    "    rules[i] = deserialize(joinpath(RULES_REPOSITORY, \"enzymes_$i\"))\n",
    "    rulesets[i] = rules[i] |> Set\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0532b7",
   "metadata": {},
   "source": [
    "We print all the resulting association rules, sorted decreasingly by global confidence, in the `results` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f3bd33",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# for each previously trained miner, we want to print the resulting rules in the\n",
    "# results folder, also reporting the meaningfulness measures\n",
    "function printreport(\n",
    "    _miner::Miner,\n",
    "    i::Int,\n",
    "    rules::Vector{ARule};\n",
    "    reportprefix::String=\"results_\"\n",
    ")\n",
    "    # we expect the experiment to consider global confidence and global lift\n",
    "    rulecollection = [\n",
    "        (\n",
    "            rule,\n",
    "            round(\n",
    "                globalmemo(_miner, (:gsupport, antecedent(rule))), digits=2\n",
    "                ),\n",
    "            round(\n",
    "                globalmemo(_miner, (:gsupport, Itemset(rule))), digits=2\n",
    "            ),\n",
    "            round(\n",
    "                globalmemo(_miner, (:gconfidence, rule)), digits=2\n",
    "            ),\n",
    "            round(\n",
    "                globalmemo(_miner, (:glift, rule)), digits=2\n",
    "            ),\n",
    "        )\n",
    "        for rule in rules\n",
    "    ]\n",
    "\n",
    "    # rules are ordered decreasingly by global lift\n",
    "    sort!(rulecollection, by=x->x[5], rev=true);\n",
    "\n",
    "    reportname = joinpath(RESULTS_REPOSITORY, \"$(reportprefix)$(i)\")\n",
    "\n",
    "    println(\"Writing to: $(reportname)\")\n",
    "\n",
    "    open(reportname, \"w\") do io\n",
    "        println(io, \"Columns are: rule, ant support, ant+cons support,  confidence, lift\")\n",
    "\n",
    "        padding = maximum(length.(_miner |> freqitems))\n",
    "        for (rule, antgsupp, consgsupp, conf, lift) in rulecollection\n",
    "            println(io,\n",
    "                rpad(rule, 8 * padding) * \" \" * rpad(string(antgsupp), 10) * \" \" *\n",
    "                rpad(string(consgsupp), 10) * \" \" * rpad(string(conf), 10) * \" \" *\n",
    "                string(lift)\n",
    "            )\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "# we print all the rules for each miner\n",
    "for i in 1:_nclasses\n",
    "    _miner = deserialize(joinpath(MINERS_REPOSITORY, \"miner_$i\"))\n",
    "    printreport(_miner, i, arules(_miner))\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
